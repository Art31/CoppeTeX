%%
%% This is file `example.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% coppe.dtx  (with options: `example')
%% 
%% This is a sample monograph which illustrates the use of `coppe' document
%% class and `coppe-unsrt' BibTeX style.
%% 
%% \CheckSum{1613}
%% \CharacterTable
%%  {Upper-case    \A\B\C\D\E\F\G\H\I\J\K\L\M\N\O\P\Q\R\S\T\U\V\W\X\Y\Z
%%   Lower-case    \a\b\c\d\e\f\g\h\i\j\k\l\m\n\o\p\q\r\s\t\u\v\w\x\y\z
%%   Digits        \0\1\2\3\4\5\6\7\8\9
%%   Exclamation   \!     Double quote  \"     Hash (number) \#
%%   Dollar        \$     Percent       \%     Ampersand     \&
%%   Acute accent  \'     Left paren    \(     Right paren   \)
%%   Asterisk      \*     Plus          \+     Comma         \,
%%   Minus         \-     Point         \.     Solidus       \/
%%   Colon         \:     Semicolon     \;     Less than     \<
%%   Equals        \=     Greater than  \>     Question mark \?
%%   Commercial at \@     Left bracket  \[     Backslash     \\
%%   Right bracket \]     Circumflex    \^     Underscore    \_
%%   Grave accent  \`     Left brace    \{     Vertical bar  \|
%%   Right brace   \}     Tilde         \~}
%%
% useful link: https://apgita.org.br/academico/teses-e-latex/
\documentclass[msc,numbers,english]{coppe} % maybe mscexam?
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{xcolor}

\makelosymbols
\makeloabbreviations

\begin{document}
  \title{Tradução de linguagem automática em português brasileiro através de redes neurais em domínios de baixo recurso}
  \foreigntitle{Tackling low resource neural machine translation applied to Brazilian Portuguese}
  \author{Arthur}{Telles Estrella}
  \advisor{Prof.}{João}{Baptista de Oliveira e Souza Filho}{D.Sc.}
  % \advisor{Prof.}{Nome do Segundo Orientador}{Sobrenome}{Ph.D.}
  % \advisor{Prof.}{Nome do Terceiro Orientador}{Sobrenome}{D.Sc.}

  \examiner{Prof.}{Nome do Primeiro Examinador Sobrenome}{D.Sc.}
  \examiner{Prof.}{Nome do Segundo Examinador Sobrenome}{Ph.D.}
  \examiner{Prof.}{Nome do Terceiro Examinador Sobrenome}{D.Sc.}
  \examiner{Prof.}{Nome do Quarto Examinador Sobrenome}{Ph.D.}
  \examiner{Prof.}{Nome do Quinto Examinador Sobrenome}{Ph.D.}
  \department{PEE}
  \date{02}{2021}

  \keyword{Primeira palavra-chave}
  \keyword{Segunda palavra-chave}
  \keyword{Terceira palavra-chave}

  \maketitle

  \frontmatter
  \dedication{A algu\'em cujo valor \'e digno desta dedicat\'oria.}

  \chapter*{Agradecimentos}

  Gostaria de agradecer a todos.

  \begin{abstract}

  Apresenta-se nesta dissertação um estudo dedicado a lidar com a tarefa de tradução usando redes neurais, em condições de pouca disponibilidade de dados e com apenas uma GPU, com foco específico para o português-inglês. 
  Será avaliado o efeito prático de técnicas disponíveis na literatura que possuem algum potencial de melhorar a performance nesse contexto, como subword embeddings, pretrained word embeddings e back translation, e como elas  impactam qualitativamente no desempenho em frases de diferentes níveis de complexidade.
  Essas técnicas terão seus prós e contras avaliados e discutidos, utilizando as principais arquiteturas utilizadas na literatura, redes neurais recorrentes e baseadas em transformers.
  (avaliar isso) O melhor modelo desenvolvido é capaz de atingir x\% de score BLEU e y de perplexidade no conjunto de teste do dataset xpto.

  \end{abstract}

  \begin{foreignabstract}

  In this work, a dedicated analysis is executed to get best practices on how to tackle neural machine translation under low data availability and using a single GPU, focusing specifically on the Portuguese-English pair. 
  Techniques in the literature that can potentially boost the performance under this context will be evaluated, such as subword embeddings, pretrained word embeddings and back translation, and the qualitative impact of them is presented in sentences with a complexity drill down.
  The tradeoffs of these techniques are discussed, contemplating the main architectures used in the literature, neural recurrent models and transformer-based ones.
  (evaluate this) The best model built is capable of reaching x\% BLEU score and y Perplexity in the test set for the xpto Portuguese dataset.

  \end{foreignabstract}

  \tableofcontents
  \listoffigures
  \listoftables
  %% --- UNDERSTAND HOW TO USE THIS ---
  \printlosymbols
  \printloabbreviations
  %% ----------------------------------
  \mainmatter
  \chapter{Introduction}
  \section{The reenactment of machine translation}
  
  The machine translation is a research field that until 2013 has mainly invested in statistical based models, but the breakthrough promoted by sequence to sequence algorithms followed by the use of transformer models has significantly changed the focus of the field. Before neural networks, machine translation systems were rules-based, syntax-based, phrase-based or a blend between more than one of these techniques. Probabilistic models were used and considered state of the art just before the first sequence to sequence paper appeared. The increase in performance promoted by the sequence to sequence and transformers quickly received some attention, and soon other variants were developed.
  
  Despite being constrained by computational power in many stages since its beginning, one of the most relevant contributions to the translation task were the transformers, which made possible to perform the computation in a truly parallel schema. With this new architecture, the operations performed during training are not totally dependent, allowing them to become parallelizable in the GPU. By removing the constraint of some operations having to wait for others to finish, NMT models were enabled to scale and reach even higher quality translations.
  
  In 3 years NMT became the dominant approach to machine translation, inducing a major transition from statistical to neural models. The broad set of parameters and architectures already present in the literature that could be used to boost translation quality, along with the promising results being presented at the time reached the interest of researchers to explore this variant.

  \section{Challenges for the Portuguese language}

  Traditionally, the machine translation datasets and conferences usually focus on a subset of languages from countries that are actively investing on NLP, which biases and narrows the potential that the algorithms have towards a specific domain. Unfortunately, Portuguese is a language that does not ostentate supervised translation data in diversity and quantity, an issue that increases the struggle to build a model that can successfully translate it to other languages. Another obstacle is that Portuguese has european, brazilian and african variants, this provides a challenge for a model since generalization is harder if several sentences with different dialects can have the same meaning.
  
  The branch of NMT inside natural language processing is also a field with few papers and academic works among Brazilian universities, this can be partially explained by the challenge that this environment presents: most models require cutting edge GPUs and usually only one GPU is not enough for medium sized model on an average WMT competition dataset. The scarcity of these resources for research purposes require students to innovate in a limited domain and search for cloud solutions without sponsorship.
  
  Finally, Portuguese is a complex language that uses accents which can change their meaning (i.e. "e" and "é"), has different pronoun organizations (i.e. "realizar-se-á" equals "se realizará") and irregular verb inflections (i.e. the "pôr" and "haver" verbs) so text preprocessing and tokenization plays an important role. Disregarding these details by applying some generic preprocessing steps that eliminates accents for instance can lead to worse model performance. On the other hand, having some domain knowledge and apply this to the NLP pipeline can help the model better translate or classify, depending on the desired task.
  
  \section{Contributions of this dissertation}
  
  The generic contribution of this work is the evaluation of a set of techniques available in the literature for NMT that can help dealing with low resource domains, although being applied to Portuguese they can be generalized to other languages. There is also a specialized contribution under a qualitative domain, as performance gains provided by these techniques are evaluated in a subset of sentences that contain a complexity drill down, enabling the reader to have a deeper understanding of their effects on the Portuguese language.

  \section{Chapter Organization}

  \textcolor{red}{(a ideia final para a dissertação do chapter 2 é falar de arquitetura e revisão teórica/bibliográfica de fundamentos da arquitetura, depois no 3 mostrar restrições que acontecem em low resource domains e suas consequencias, com revisão bibliográfica das técnicas disponíveis que podem ajudar nesse contexto e a motivação das escolhas feitas)}

  An explanation of the transformer and recurrent neural network architectures and how researchers iterated on them to become state of the art is given in chapter 2.
  
  In chapter 3 constraints that arise in low resource domains and a review of techniques that can potentially help to reduce those issues are presented, along with the rationale behind our choices.
  
  The datasets chosen are presented in chapter 4, where we also describe implementation details, how hyperparameters were iterated on to fit in a single machine GPU and results of the experiments, which are measured in terms of validation perplexity, BLEU and \textcolor{red}{TER(?)(<to be defined>)}. A qualitative discussion regarding human and model translations in different complexity levels is also performed.
  
  \textcolor{red}{(Finally, in chapter 5 this work is concluded and further improvements and study directions are outlined.)}
  
  Finally, in chapter 5, next steps to conclude this work in the following months are presented

  \chapter{Neural networks and machine translation}

  Since their ideation in 1958, neural networks have seen peaks and valleys of research focus in many different artificial intelligence fields. After going out of the tar pit in the 1980s with feedforward and recurrent variants, receiving convolutional and LSTM variants in 1990s, they started to leverage promising results when applied to numerical and categorical data. Specially after 2013 neural networks were growing at an unseen rate, applications to image processing and natural language processing were massively explored and soon consolidated themselves as state of the art algorithms. 
  
  Among the first relevant contributions coming from neural networks to the NLP domain was \citet{mikolov2013efficient}, that managed to execute the task of efficiently adjusting word vectors in a N dimensional space using a 2 layer shallow neural network. This was accomplished by adjusting word vectors based on the likelihood of a word to occur given a context or vice versa.
  
  For a long time, this paradigm hasn't seen any applications to solve translation tasks, until 2013 when \citet{cho-etal-2014-learning} came up with a RNN Encoder-Decoder architecture proposal. The focus of the scientific community at the time that was on statistical models, but as the application of recurrent networks to this domain gained maturity, the papers gradually started to switch their focus.
  
  \section{Recurrent neural networks as machine translators}

  In Cho et al's approach, one RNN reads each symbol of an input sequence x sequentially and encodes this sequence of symbols into a fixed-length vector representation $c$, the hidden state. The other decodes this representation into another sequence of symbols by predicting the next symbol $y_{t}$ given the hidden state $h_{{t}}$. The equation for the decoder's hidden state at time $t$ is given below.

  \begin{equation}
  h_{{t}} = f(h_{t-1}, y_{t-1}, c)
  \end{equation}
  
  In this setup, the encoder and decoder of the proposed model are jointly trained to maximize the conditional log-likelihood of a target sequence given a source sequence. It has the drawback of losing some of the information provided by the encoder, since only the hidden state is used, and the RNN output is discarded. Another issue is that the neural network has to compress all the necessary information of a source sentence into a fixed-length vector, which provides a challenge to deal with long sentences.

  \subsection{Bahdanau's attention mechanism}

  To address the fixed-length and "information compression" loss issues identified in the previous implementation, the authors of the first paper proposed another way of connecting the encoder to the decoder \citet{bahdanau2016neural}, where the former encodes the input sequence into a sequence of vectors and extracts a subset of these vectors (not a single fixed-length one), while decoding the translation.
  
  The encoder output (also called context vector) $c_{t}$ is now a variable length vector that represents annotations and comprises a mechanism that extract information from different parts of the input sentence. Each annotation receives a weight and the final vector built can be seen as a weighted average of the inputs, where these weights represent a way to distribute attention. 
  
  This attention mechanism can be also interpreted as an alignment model, that directly computes a soft alignment, which allows the gradient of the cost function to be backpropagated through. This gradient can be used to train the alignment model as well as the whole translation model jointly, and this new information flow partially explains the performance gains reported.
  
  Another improvement that contributed to the success of this approach is the use of bidirectional RNNs to encode the input sequence, the vector that flows from the encoder to the decoder now contains a representation not only of the preceding words but also of the following words, allowing a more efficient attention weight distribution. Despite these improvements, the attention mechanism is still rather simple and does not accomplish the importance attribution task as well as its succeeding variants, implemented in other papers later on.
  
  \textcolor{red}{(equations from the paper will be put in here later to matematically explain how attention is distributed)}
  
  An interesting work that explores the potential the previous presented RNN models have is executed by \citet{britz2017massive}, where using \cite{cho-etal-2014-learning} as a base model, several hyperparameters like embedding size, RNN cell variant (LSTM and GRU), encoder and decoder depth, unidirectional vs. bidirectional RNN encoders, attention mechanism and beam search parameters are iterated and findings about the best setups are reported. One of the claims of this work is that careful hyperparamter tuning can yield better results than many others that explored architecture variations.
  
  Among interesting results reported on \citet{britz2017massive} are that larger embeddings consistently outperforms smaller ones by a thin margin, LSTM cells consistently outperformes GRU cells, deeper decoders tend to lead to performance increases, additive attention achieves slightly better results than multiplicative and beam searches tuned to a "sweet spot" can increase model performance up to 5\%. Some of these conclusions are incorporated into our hyperparameters also, but given the low resource domain constraints and other features to iterate, our hyperparameter search is a bit narrower.

  \section{Transformer-based models}
  
  A relevant contribution to a field that at the time was mainly iterating in recurrent and convolution based neural networks for machine translation was made in 2017 by \citet{DBLP:journals/corr/VaswaniSPUJGKP17}. This new proposed family of transformer models is not constrained by the same condition as RNNs, which as a consequence of its sequential pattern, has to wait for an operation to finish to begin another one. This new approach gained traction and adherece from the community since parallelization was a strength, along with it came the potential to explore possible variations.
  
  In the original implementation, the encoder and the decoder contain 6 stacked transformer layers. In the encoder, each layer contains a multi-head self-attention mechanism, followed by layer normalization and a feed-forward layer. The structure in the decoder is quite similar, although an extra masked multi-head attention layer is added over the output of the encoder stack before multi-head attention. Backpropagation operates end-to-end in this architecture.
  
  The attention mechanism differs from previous implementations, but the goal is the same: to enable the model to distribute the influences of every input on the outputs generated. It can be described as mapping a query and a set of key-value pairs to an output, where the query (Q), keys (K) and values (V) are all vectors with dimensions defined by a hyperparameter. The original paper implements scaled dot product attention, computing dot products of the queries with all keys, then dividing by a normalizing factor $\sqrt{d_{k}}$ and passing this result into a softmax.
  
  \textcolor{red}{(equations from the paper will be put in here later to matematically explain attention)}
  
  Multi-head self-attention also plays a role on the contribution given by the authors, they claim that it is beneficial to project the matrices Q, K and V in attention h times, with different learned projections by each one of the heads. The projections of each head are concatenated and the attention weights now are adjusted to different representation subspaces at different positions, which at the beginning was thought to be consistently contributing to performance. Years later after an analysis performed by \citet{DBLP:journals/corr/abs-1905-09418}, this hypothesis was rejected. 
  
  The authors evaluated how the contribution of each attention head happened during the training process, and they find that only a small subset of heads are enough to sustain the transformer translation scores. They analyse the importance distribution and discover that several heads learn similar dependency mappings. By using this map as a qualitative signal of feature importance per head, they propose to prune the heads that have similar dependency maps and conclude that there is no noticeable loss in translation quality by doing this. 
  
  This paper raises a relevant question to the community: are deep learning works usually biased to increasing complexity and model parameters unnecessarily? Efficient models have a smaller carbon footprint and energy waste, which can lower the impact on nature, this could bring the community closer to the green AI status and increase credibility of deep learning research.

  \section{Attention variants for sequence to sequence learning}
  
  Not only architecture related parameters can lead the transformer to better quality translations, the attention mechanism also has attracted the interest of some contributions. Despite the evidence provided that increasing the number of heads in attention mechanisms may generate redundancy, there are works that report better results going against this advice by creating multiple attention branches, where each branch is an independent multi-head attention mechanism \cite{DBLP:journals/corr/abs-2006-10270}. 
  
  In this paper, other techniques such as a drop branch mechanism (similar as dropout, but applied to branches) and a specific initialization recipe for each branch may have an effect on the final outcome, so it is not clear whether the benefits come from multiplying attention or from those techniques.
  
  Iterations on the set of words that attention sees and on the weight distribution function are among the most common variants. In the paper published by \citet{luong-etal-2015-effective}, the attention mechanism is split into 2 classes: global and local attention. The former always attends to all source words of a given sentence, while the latter only looks at a subset of words at a given time. 
  
  Local attention is explored with different alignments, monotonic and predictive. In the first case, they just assume that source and target sequences are roughly monotonically aligned and concatenate the current hidden state with the source hidden state. For the predictive variant, they use a gaussian distribution centered around the word to be predicted and define alignment weights based on this distribution, adjusting the variation behaviour of weights to follow a normal distribution.
  
  The main contributions are that attention-based models usually outperform non-attentional ones and that a small increase in performance can be observed by adding a custom weight function (gaussian-based in this case). Also, using an ensemble of attention architectures may be also effective as they claim new state of the art results by doing so, even though further details of this ensemble are not provided.
  
  Integrating attention mechanisms with different attention perspectives is another exploited approach, which has been followed by \citet{calixto-etal-2017-doubly} and \citet{cui-etal-2019-mixed}. In the former, a single layer feedforward network is used to compute the expected alignment between each annotation vector in both mechanisms, but this increases the amount of parameters to train the model. In the latter, the concept of forward and backward attention is introduced, where specialized masks help the transformer to model word other information in a slightly different schema of the positional encoder used in the original paper. Both mechanisms are concatenated with the standard global and local attention, although this leads to better BLEU it also increases model parameters.
  
  There is no evidence that iterating on the attention mechanism would provide any benefits in low resource settings, furthermore all iterations usually increase model paremeters, hence hindering our low resource scenario. This together with the fact that data augmentation and embedding techniques have better potential, no iterations were made on the traditional attention mechanism of RNNs and transformers in this work.
  
  \section{How far transformers can go? Which changes are the most promising?}
  
  Talk briefly of GPT, maybe bert, and other transformer variations, including using word embeddings 
  
  GPT-3 \citet{brown2020language}
  
  DeFINE: DEep Factorized INput Word Embeddings for Neural Sequence \citet{DBLP:journals/corr/abs-1911-12385}
  
  DeLighT: Deep and Light-weight Transformer \citet{mehta2021delight}
  
  \subsection{Alternative training objectives}
  
  Despite many state of the art models having reached their scores using the original maximum likelihood estimation learning objective, the work of \citet{ranzato-sequence} indicate two drawbacks of using it in NMT. First, during training NMT models are not exposed to their translation errors, this phenomenon is referred to as exposure bias. Finally, the MLE estimation is defined at word level rather than sentence level, so theoretically the optimization objective is not aligned with the final objective, which is to generate a sentence that can match a human translation. 
  
  With this problem in mind, they introduce Mixed Incremental Cross Entropy Reinforce (MIXER), which switches the learning objective towards sentence-level training. This algorithm tries to handle the problem of backpropagating gradients on non-differentiable metrics such as BLEU with some ideas borrowed from reinforcement learning (RL). 
  
  Another technique proposed by \citet{shen-etal-2016-minimum} reported results that also raised more awareness to this learning objective issue. They claim that as MIXER samples only one candidate to calculate the reward while MRT generates multiple samples, this potentially increases its capability of discrimination, pretty close to the effect of increasing beam search in a standard NMT setup.
 
  Apart from the efforts put into iterating on the learning objective and benefits claimed by these papers, some side effects of switching the training objective are also diagnosed by \citet{DBLP:journals/corr/abs-1907-01752}. They point out the weakness of RL based approaches for optimization, claim that some of the increases are not fully attributed to the techniques and also discuss convergence issues of these new objectives. Given this unclear scenario of how iterating on the learning objective can lead to better translations, changing it in our work was not taken into consideration.

  \chapter{Low resource context}
  

  \section{low resource techniques}   
  
  decide where to put this ----
  Transfer Learning for Low-Resource Neural Machine Translation \citet{zoph-etal-2016-transfer}
  
  Revisiting Low-Resource Neural Machine Translation: A Case Study \citet{sennrich-zhang-2019-revisiting}
  ------------------------
  
  \subsection{Pretrained word embeddings}
  
  When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation? \citet{qi-etal-2018-pre} 
  
  Enriching Word Vectors with Subword Information (fast text) \citet{DBLP:journals/corr/BojanowskiGJM16}
  
  \subsection{Subword embeddings}
  
  BPE \citet{DBLP:journals/corr/SennrichHB15} 
  
  Sentence piece \citet{DBLP:journals/corr/abs-1808-06226}
  
  Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models \citet{DBLP:journals/corr/LuongM16}
  
  Talk of using Glove, word2vec, fasttext and others
  
  \subsection{Data Augmentation}
  
  Improving Neural Machine Translation Models with Monolingual Data \citet{DBLP:journals/corr/SennrichHB15a}
  
  Generalized Data Augmentation for Low-Resource Translation \citet{DBLP:journals/corr/abs-1906-03785}
 
  \chapter{Results}
  
  \section{Methodology}
  
  \section{Qualitative evaluation}
  
  \subsection{Translation metrics with complexity drill down}

  \chapter{Next steps for this dissertation}
  
  Preliminary deadline at 10/09/2021
  
  
  Segundo a norma de formata{\c c}\~ao de teses e disserta{\c c}\~oes do
  Instituto Alberto Luiz Coimbra de P\'os-gradua{\c c}\~ao e Pesquisa de
  Engenharia (COPPE), toda abreviatura deve ser definida antes de
  utilizada.\abbrev{COPPE}{Instituto Alberto Luiz Coimbra de P\'os-gradua{\c
  c}\~ao e Pesquisa de Engenharia}

  Do mesmo modo, \'e imprescind\'ivel definir os s\'imbolos, tal como o
  conjunto dos n\'umeros reais $\mathbb{R}$ e o conjunto vazio $\emptyset$.
  \symbl{$\mathbb{R}$}{Conjunto dos n\'umeros reais}
  \symbl{$\emptyset$}{Conjunto vazio}

  \begin{longquote}
  Um exemplo de citação longa nas regras da ABNT (4cm de recuo e fonte menor)
  feita com o ambiente  \verb=longquote= The primary objective of this
  investigation was to determine the feasibility of detecting corrosion in
  aluminum Naval aircraft components with neutron radiographic interrogation
  and the use of standard corrosion penetrameters. Secondary objectives
  included the determination of the effect of object thickness on image quality,
  the defining of minimum levels of detectability and a preliminary investigation
  of a means whereby the degree of corrosion could be quantified with neutron
  radiographic data.
  \end{longquote}

  Para ilustrar a completa ades\~ao ao estilo de cita{\c c}\~oes e listagem de
  refer\^encias bibliogr\'aficas, a Tabela~\ref{tab:citation} apresenta cita{\c
  c}\~oes de alguns dos trabalhos contidos na norma fornecida pela CPGP da
  COPPE, utilizando o estilo num\'erico.

  \begin{table}[h]
  \caption{Exemplos de cita{\c c}\~oes utilizando o comando padr\~ao
    \texttt{\textbackslash cite} do \LaTeX\ e
    o comando \texttt{\textbackslash citet},
    fornecido pelo pacote \texttt{natbib}.}
  \label{tab:citation}
  \centering
  {\footnotesize
  \begin{tabular}{|c|c|c|}
    \hline
    Tipo da Publica{\c c}\~ao & \verb|\cite| & \verb|\citet|\\
    \hline
    Livro & \cite{book-example} & \citet{book-example}\\
    Artigo & \cite{article-example} & \citet{article-example}\\
    Relat\'orio & \cite{techreport-example} & \citet{techreport-example}\\
    Relat\'orio & \cite{techreport-exampleIn} & \citet{techreport-exampleIn}\\
    Anais de Congresso & \cite{inproceedings-example} &
      \citet{inproceedings-example}\\
    S\'eries & \cite{incollection-example} & \citet{incollection-example}\\
    Em Livro & \cite{inbook-example} & \citet{inbook-example}\\
    Disserta{\c c}\~ao de mestrado & \cite{mastersthesis-example} &
      \citet{mastersthesis-example}\\
    Tese de doutorado & \cite{phdthesis-example} & \citet{phdthesis-example}\\
    \hline
  \end{tabular}}
  \end{table}

  \chapter{Results}
  
  \section{Datasets}
  
  Apart from the issues outlined, there is a collaborative dataset created and maintained by the Tatoeba Project that contains several English-Portuguese sentence pairs, that is available on the internet. The project contains datasets with several bilingual sentence pairs, considered to match an intermediate english level and translated from English to several other languages, including Portuguese. The Portuguese dataset contains 165k sentences, with 993k words and 21k unique words. It was built by native speakers and has been reviewed by a linguistic expert.

  When compared to the average WMT datasets, it is not as large and the vocabulary size is a bit smaller, so it is considered medium level dataset to machine translation, but it suffices our needs.
  
  \chapter{Conclusions}

  \backmatter
  \bibliographystyle{coppe-unsrt}
  \bibliography{example}

  \appendix
  \chapter{Algumas Demonstra{\c c}\~oes}
\end{document}
%% 
%%
%% End of file `example.tex'.
